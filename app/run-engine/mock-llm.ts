// ---------------------------------------------------------------------------
// MockLLM — simulated LLM executor for the RunEngine
// ---------------------------------------------------------------------------
//
// MockLLM acts as a drop-in executor for RunEngine.startRun(). After a
// configurable delay it resolves to either a result or a clarifying question,
// mirroring the two possible outcomes of a real LLM call.
//
// Usage:
//   const mock = new MockLLM('Alice', 'Explorer', 'Map the north sector')
//   engine.startRun(run.id, mock.asExecutor())
//
// The returned executor produces a MockLLMResponse that the RunEngine routes:
//   { kind: 'result', text }   → run transitions to 'completed'
//   { kind: 'question', text } → run transitions to 'awaiting'
// ---------------------------------------------------------------------------

import type { MockLLMResponse } from './types'
import { generateResult, generateQuestion } from './results'

/** Construction options for MockLLM. */
export interface MockLLMOptions {
  /**
   * Probability [0, 1] that the simulated response is a clarifying question
   * rather than a completion result.
   * Default: 0.3 (30 % chance of question, 70 % chance of result).
   */
  questionProbability?: number
  /** Minimum simulated processing delay in milliseconds. Default: 2000. */
  minDelayMs?: number
  /** Maximum simulated processing delay in milliseconds. Default: 6000. */
  maxDelayMs?: number
  /**
   * Custom delay calculator — receives min and max and returns the actual
   * delay in ms. Defaults to a uniform random value in [minDelayMs, maxDelayMs].
   * Override in tests to control timing deterministically.
   */
  delayFn?: (minMs: number, maxMs: number) => number
}

/** Default delay: uniform distribution in [minMs, maxMs]. */
function defaultDelayFn(minMs: number, maxMs: number): number {
  return minMs + Math.random() * (maxMs - minMs)
}

// ---------------------------------------------------------------------------
// MockLLM
// ---------------------------------------------------------------------------

/**
 * Simulated LLM that produces a `MockLLMResponse` after a configurable delay.
 *
 * - With probability `questionProbability` (default 0.3) it returns a
 *   clarifying question (`kind: 'question'`).
 * - Otherwise it returns a completion result (`kind: 'result'`).
 *
 * Both the result text and question text are generated by the same pure
 * template functions used by the RunEngine's built-in mock mode, so the
 * output is contextualised with the agent's name, role, and task.
 *
 * The key difference from the built-in mock is that MockLLM is a first-class
 * executor: it can be composed, configured, and tested independently of the
 * RunEngine, and it exposes `asExecutor()` to integrate with `startRun()`.
 */
export class MockLLM {
  private readonly _agentName: string
  private readonly _agentRole: string
  private readonly _taskDescription: string
  private readonly _questionProbability: number
  private readonly _minDelayMs: number
  private readonly _maxDelayMs: number
  private readonly _delayFn: (minMs: number, maxMs: number) => number

  constructor(
    agentName: string,
    agentRole: string,
    taskDescription: string,
    options: MockLLMOptions = {},
  ) {
    this._agentName = agentName
    this._agentRole = agentRole
    this._taskDescription = taskDescription
    this._questionProbability = options.questionProbability ?? 0.3
    this._minDelayMs = options.minDelayMs ?? 2_000
    this._maxDelayMs = options.maxDelayMs ?? 6_000
    this._delayFn = options.delayFn ?? defaultDelayFn
  }

  /**
   * Simulate LLM processing and resolve with a result or a question.
   *
   * The promise resolves (never rejects) after the configured delay.
   * Use `asExecutor()` to pass this directly to `RunEngine.startRun()`.
   */
  run(): Promise<MockLLMResponse> {
    const delayMs = this._delayFn(this._minDelayMs, this._maxDelayMs)
    return new Promise<MockLLMResponse>((resolve) => {
      setTimeout(() => {
        if (Math.random() < this._questionProbability) {
          resolve({
            kind: 'question',
            text: generateQuestion(this._agentName, this._agentRole, this._taskDescription),
          })
        } else {
          resolve({
            kind: 'result',
            text: generateResult(this._agentName, this._agentRole, this._taskDescription),
          })
        }
      }, delayMs)
    })
  }

  /**
   * Return a `RunExecutor`-compatible function wrapping `this.run()`.
   *
   * @example
   * const mock = new MockLLM(agentName, agentRole, task)
   * engine.startRun(run.id, mock.asExecutor())
   */
  asExecutor(): () => Promise<MockLLMResponse> {
    return () => this.run()
  }
}
